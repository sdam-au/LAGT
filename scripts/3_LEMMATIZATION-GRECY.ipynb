{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "import sddk\n",
    "import re\n",
    "import regex\n",
    "import unicodedata\n",
    "from greek_accentuation.characters import strip_accents\n",
    "from greek_accentuation.syllabify import *\n",
    "from greek_accentuation.accentuation import *"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-17T13:16:03.935998Z",
     "start_time": "2024-01-17T13:16:03.930761Z"
    }
   },
   "id": "initial_id",
   "execution_count": 183
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vojtechkase/Projects/LAGT/lagt_venv/lib/python3.10/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'grc_proiel_trf' (3.6.0) was trained with spaCy v3.6.0 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "#! ../lagt_venv/bin/python -m pip install grecy\n",
    "#! ../lagt_venv/bin/python -m grecy install grc_proiel_trf\n",
    "nlp = spacy.load('grc_proiel_trf')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T21:40:52.425527Z",
     "start_time": "2024-01-16T21:40:48.034878Z"
    }
   },
   "id": "99ee7d5a540463a4",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "nlp = spacy.load('grc_proiel_trf')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T21:40:58.720911Z",
     "start_time": "2024-01-16T21:40:54.924378Z"
    }
   },
   "id": "803c4e68d5d72d09",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "doc = nlp('δοκῶ μοι περὶ ὧν πυνθάνεσθε οὐκ ἀμελέτητος εἶναι')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T21:41:03.523860Z",
     "start_time": "2024-01-16T21:41:03.445342Z"
    }
   },
   "id": "6893b03e830b613a",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "δοκῶ δοκέω\n",
      "μοι ἐγώ\n",
      "περὶ περί\n",
      "ὧν ὅς\n",
      "πυνθάνεσθε πυνθάνομαι\n",
      "οὐκ οὐ\n",
      "ἀμελέτητος ἀμελέτητος\n",
      "εἶναι εἰμί\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('δοκῶ μοι περὶ ὧν πυνθάνεσθε οὐκ ἀμελέτητος εἶναι')\n",
    "for t in doc:\n",
    "    print(t.text, t.lemma_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T21:41:31.682789Z",
     "start_time": "2024-01-16T21:41:31.674947Z"
    }
   },
   "id": "2a4b939dba2cda07",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "LAGT = pd.read_json(\"../data/large_files/LAGT_treebanks_20240116.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T21:57:10.345604Z",
     "start_time": "2024-01-16T21:57:05.506258Z"
    }
   },
   "id": "819aef2568d1ded9",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "### greCy Test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9a2ec8323f35fbf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "string = LAGT[LAGT[\"lemmatized_sentences\"].isnull()][\"string\"].tolist()[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T13:25:26.346876Z",
     "start_time": "2024-01-17T13:25:26.339267Z"
    }
   },
   "id": "e9afdc81ad0b3b53",
   "execution_count": 208
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Χρὴ', 'γιγνώσκω', 'γῆ', 'περίμετρος']\n",
      "['στάδιος', 'μυριάς']\n",
      "['μῆκος']\n",
      "['ἡμέτερος', 'οἰκουμένη', 'στόμα', 'Γάγγης', 'Γαδείρων', 'στάδιον']\n",
      "[]\n",
      "['πλάτος', 'Αἰθιοπικός', 'θάλασσα', 'Τανάϊδος', 'ποταμός', 'στάδιον']\n",
      "['Εὐφράτης', 'Τίγρις', 'ποταμός', 'καλέω', 'Μεσοποτάμιος', 'διάστημα', 'ἔχω', 'στάδιον']\n",
      "[]\n",
      "['ἀναμέτρησις', 'ποιέω', 'Ἐρατοσθένης', 'ἀρχαῖος', 'μαθητικώτατος']\n",
      "[]\n",
      "['Βυζάντιον', 'Σωσθένιος', 'στάδιον', 'μίλιον', 'ἥμισυς']\n",
      "[]\n",
      "['Σωσθενίας', 'Ἱερόν', 'στάδιον', 'μίλιον']\n",
      "['ἥμισυς']\n",
      "['πᾶς', 'μίλιον']\n",
      "[]\n",
      "['Ἱερόν', 'Ζεύς', 'Οὐρῖος', 'στόμα', 'Πόντος', 'ἱερόν', 'στόμα', 'Ἴστρος', 'ποταμός', 'στάδιον', 'μίλιον', 'ἥμισυς']\n",
      "[]\n",
      "['Ἱερόν', 'Ζεύς', 'Οὐρίης', 'Βορυσθένης', 'ποταμός', 'Δανάπρις', 'καλέω', 'στάδιον']\n",
      "['μίλιον']\n",
      "[]\n",
      "['ἥμισυς']\n",
      "['Ἱερόν', 'Ζεύς', 'Οὐρίης', 'Πορθμῖος', 'πόλις', 'τέλος', 'Εὐρώπη', 'Πόντος', 'μέρος', 'στομίον', 'Μαιώτης', 'λίμνη', 'Βόσπορος', 'Κιμμερῖος', 'καλέω', 'στάδιον']\n",
      "['μίλιον']\n",
      "[]\n",
      "['λέγω', 'Εὐρώπη', 'Ποντικός', 'περίπλοος', 'ἴσος', 'περίπλοος', 'Ἀσία', 'μέρος']\n",
      "['Ἱερόν', 'Ζεύς', 'Οὐρίης', 'Ἀμισός', 'στάδιον', 'μίλιον']\n",
      "['ἥμισυς']\n",
      "['Ἀμισός', 'Φάσις', 'ποταμός']\n",
      "['στάδιον', 'μίλιον']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['Φάσις', 'ποταμός']\n",
      "['στόμα', 'Μαιώτης', 'λίμνη', 'Ἀχιλλείος', 'κώμη', 'στάδιον']\n",
      "['μίλιον', 'ἥμισυς', 'γίγνομαι', 'Ἱερόν', 'Ζεύς', 'Οὐρίης', 'στόμα', 'Μαιώτης', 'λίμνη', 'στάδιον']\n",
      "['μίλιον']\n",
      "[]\n",
      "['ἥμισυς']\n",
      "[]\n",
      "['γίγνομαι', 'περίπλοος', 'εὔξενος', 'Πόντος', 'δεξιός', 'Ἀσία', 'μέρος', 'Πόντος', 'ἀριστερός', 'Εὐρώπη', 'μέρος', 'Πόντος', 'Ἱερόν', 'Ζεύς', 'Οὐρῖος', 'στάδιον']\n",
      "[]\n",
      "[]\n",
      "['μίλιον']\n",
      "[]\n",
      "[]\n",
      "['περίπλοος', 'Μαιώτης', 'λίμνη', 'στάδιον', 'μίλιον', 'στάδιον', 'στάδιον', 'πῆχυς', 'ἔχω', 'πούς', 'ὀργυιά', 'ἥμισυς']\n",
      "[]\n",
      "['μιλῖος']\n",
      "['μίλιον', 'ἔχω', 'στάδιον', 'ἥμισυς', 'πῆχυς', 'πούς']\n",
      "[]\n",
      "['ἐνιαυτός', 'Ἅπας', 'ἔχω', 'ὥρα']\n",
      "['ἡμέρα', 'τέταρτος']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(string)\n",
    "for sent in doc.sents:\n",
    "    print([t.lemma_ for t in sent if t.pos_ in [\"NOUN\", \"ADJ\", \"VERB\", \"PROPN\"]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T13:25:28.006481Z",
     "start_time": "2024-01-17T13:25:26.887654Z"
    }
   },
   "id": "3fd501624bd50956",
   "execution_count": 209
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's improve it: preclean the string and make it suitable to work with large documents"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f37021820a5dff2c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_doc(string, segment_len=100000):\n",
    "    if len(string) > segment_len:\n",
    "        segment = string[:segment_len]\n",
    "        matches = [(m.start(0), m.end(0)) for m in re.finditer('(\\.\\s|·\\s)', segment)]\n",
    "        if matches:\n",
    "            split_at = matches[-1][1]  # taking the end index of last match\n",
    "            current_segment = segment[:split_at]\n",
    "            next_segment_beginning = segment[split_at:]\n",
    "        else:\n",
    "            current_segment = segment\n",
    "            next_segment_beginning = \"\"\n",
    "\n",
    "        segment_doc = nlp(current_segment)\n",
    "        segment_docs = [segment_doc]\n",
    "\n",
    "        for n in range(segment_len, len(string), segment_len):\n",
    "            segment = string[n:n+segment_len]\n",
    "            if len(segment) == segment_len:\n",
    "                matches = [(m.start(0), m.end(0)) for m in re.finditer('(\\.\\s|·\\s)', segment)]\n",
    "                if matches:\n",
    "                    split_at = matches[-1][1]\n",
    "                    current_segment = next_segment_beginning + segment[:split_at]\n",
    "                    next_segment_beginning = segment[split_at:]\n",
    "                else:\n",
    "                    current_segment = next_segment_beginning + segment\n",
    "                    next_segment_beginning = \"\"\n",
    "            else:\n",
    "                current_segment = next_segment_beginning + segment\n",
    "\n",
    "            segment_doc = nlp(current_segment)\n",
    "            segment_docs.append(segment_doc)\n",
    "\n",
    "        doc = Doc.from_docs(segment_docs)\n",
    "    else:\n",
    "        doc = nlp(string)\n",
    "    return doc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T13:26:16.887233Z",
     "start_time": "2024-01-17T13:26:16.872649Z"
    }
   },
   "id": "ce3761c4fdcf64b9",
   "execution_count": 210
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'p. 980 a 22 Πάντες ἄνθρωποι τοῦ εἰδέναι ὀρέγονται φύσει. σημεῖον\\n δὲ ἡ τῶν αἰσθήσεων ἀγάπησις. Δεῖ ἡμᾶς ἀρχομένους τῆς παρούσης πραγματείας εἰπεῖν τὸν σκοπόν,\\nτὴν τάξιν,. τὴν αἰτίαν τῆς ἐπιγραφῆς. σκοπὸς μὲν οὖν ἐστι τῆς παρούσης\\nπραγματείας τὸ θεολογῆσαι· θεολογεῖ γὰρ ἐν αὐτῇ Ἀριστοτέλης. ἡ δὲ τάξις,\\nὅτι ἐκ τῶν φύσει ὑστέρων ἡμεῖς τὰς ἀρχὰς ποιούμεθα, ἐπειδὴ ταῦτα μᾶλλον\\n συνεγνωσμένα ἡμῖν ὑπάρχουσι. διὰ τοῦτο τοίνυν ὁ Ἀριστοτέλης πρότερον\\nδιελέχθη ἡμῖν περὶ τῶν φυσικῶν πραγμάτων· ταῦτα γὰρ τῇ φύσει ὕστερα\\nὑπάρχουσιν, ἡμῖν δὲ πρότερα. ἡ δὲ παροῦσα πραγματεία τῇ μὲν φύσει\\nπροτέρα ὧς τὸ τέλειον ἔχουσα, ἡμῖν δὲ ὑστέρα· πρότερα γὰρ τὰ ἄφθαρτα\\nτῶν φθαρτῶν καὶ τὰ ἀγένητα τῶν γινομένων. διὰ τοῦτο τοίνυν ὁ Ἀριστοτέλης\\n πρότερον διελέχθη ἡμῖν περὶ τῶν ἀτάκτως κινουμένων ἐν τοῖς Μετεώροις,\\nκαὶ πάλιν περὶ τῶν τεταγμένως κινουμένων ἐν τῇ Περὶ οὐρανοῦ,\\nφημὶ δὴ περὶ ἀστέρων καὶ σφαιρῶν· καὶ λοιπὸν ἐν ταύτῃ τῇ πραγματείᾳ\\nδιαλέγεται ἡμῖν περὶ τῶν πάντῃ ἀκινήτων. τοῦτο δέ ἐστι θεολογία · τοῖς\\nγὰρ θείο'"
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check with some of the longest document we have...\n",
    "string = LAGT[LAGT[\"lemmatized_sentences\"].isnull()].sort_values(\"wordcount\", ascending=False)[\"string\"].tolist()[23]\n",
    "string[:1000]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T13:26:28.130938Z",
     "start_time": "2024-01-17T13:26:28.124849Z"
    }
   },
   "id": "ce939bee0e921e30",
   "execution_count": 211
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# functioms for cleaning the string\n",
    "\n",
    "def grave_to_acute(string):\n",
    "    GRAVE = \"\\u0300\"\n",
    "    ACUTE = \"\\u0301\"\n",
    "    return unicodedata.normalize(\"NFC\", \"\".join(unicodedata.normalize(\"NFD\", string).replace(GRAVE, ACUTE)))\n",
    "\n",
    "def possible_accentuation(morph):\n",
    "    try:\n",
    "        if isinstance(morph, str):\n",
    "            morph = strip_accents(morph)\n",
    "            morph = rebreath(morph)\n",
    "            s = syllabify(morph)\n",
    "            for accentuation in possible_accentuations(s, default_short=True):\n",
    "                pos, accent = accentuation\n",
    "                final = s[1 - pos:] if pos > 1 else [\"\"]\n",
    "                morph_acc_var = \"\".join(s[:-pos] + [syllable_add_accent(s[-pos], accent)] + final)\n",
    "                return morph_acc_var  # Return the first accentuation immediately\n",
    "        return morph  # If no accentuation is available, return the original morph\n",
    "    except:\n",
    "        return morph\n",
    "\n",
    "def decap(token):\n",
    "    if len(token) > 1:\n",
    "        if token[1].isupper():\n",
    "            token = token[0] + token[1:].lower()\n",
    "            token = possible_accentuation(token)\n",
    "    return token\n",
    "\n",
    "def clean_string(string):\n",
    "    string = re.sub(\"ϲ(\\W)\", r\"ς\\1\", string) # if \"ϲ\" is last letter of a word\n",
    "    string = re.sub(\"ϲ(\\w)\", r\"σ\\1\", string)\n",
    "    string = grave_to_acute(string)\n",
    "    pattern = r'[^\\p{Script=Greek}\\p{P}\\s]+'\n",
    "    cleaned_string = regex.sub(r'[^\\p{Greek}\\p{P}]', ' ', string)\n",
    "    cleaned_string = \" \".join([decap(token) for token in cleaned_string.split()])\n",
    "    cleaned_string = regex.sub(' +', ' ', cleaned_string)\n",
    "    cleaned_string = cleaned_string.replace(\"·\", \".\")\n",
    "    return cleaned_string"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T13:27:02.526883Z",
     "start_time": "2024-01-17T13:27:02.521983Z"
    }
   },
   "id": "fd0fd59452308978",
   "execution_count": 214
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T13:27:02.857979Z",
     "start_time": "2024-01-17T13:27:02.852733Z"
    }
   },
   "id": "6b8a813cd613764",
   "execution_count": 214
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%time\n",
    "doc = get_doc(clean_string(string), segment_len=50000)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-17T13:27:20.347638Z"
    }
   },
   "id": "5b61ecd54152df4c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# extract lemmata from the sentences\n",
    "def get_lemmatized_sentences(doc):\n",
    "    lemmatized_sentences = []\n",
    "    for sent in doc.sents:\n",
    "        sentence_lemmata = [regex.sub(r'[^\\p{Greek}]', \"\", t.lemma_) for t in sent if t.pos_ in [\"NOUN\", \"VERB\", \"ADJ\", \"PROPN\"]]\n",
    "        sentence_lemmata = [t for t in sentence_lemmata if t != \"\"]\n",
    "        if sentence_lemmata != []:\n",
    "            lemmatized_sentences.append(sentence_lemmata)\n",
    "    return lemmatized_sentences"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "22927430852de058",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# put the string cleaning, doc creation and lemmata together into one function\n",
    "def from_string_to_lemsents(string):\n",
    "    doc = get_doc(clean_string(string), segment_len=50000)\n",
    "    lemmatized_sentences = get_lemmatized_sentences(doc)\n",
    "    return lemmatized_sentences"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "61b2d35b56c90ac5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E088] Text of length 1419780 exceeds maximum of 1000000. The parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. This means long texts may cause memory allocation errors. If you're not using the parser or NER, it's probably safe to increase the `nlp.max_length` limit. The limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[0;32m<timed exec>:10\u001B[0m\n",
      "File \u001B[0;32m~/Projects/LAGT/lagt_venv/lib/python3.10/site-packages/pandas/core/frame.py:10037\u001B[0m, in \u001B[0;36mDataFrame.apply\u001B[0;34m(self, func, axis, raw, result_type, args, by_row, **kwargs)\u001B[0m\n\u001B[1;32m  10025\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapply\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m frame_apply\n\u001B[1;32m  10027\u001B[0m op \u001B[38;5;241m=\u001B[39m frame_apply(\n\u001B[1;32m  10028\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m  10029\u001B[0m     func\u001B[38;5;241m=\u001B[39mfunc,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m  10035\u001B[0m     kwargs\u001B[38;5;241m=\u001B[39mkwargs,\n\u001B[1;32m  10036\u001B[0m )\n\u001B[0;32m> 10037\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapply\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Projects/LAGT/lagt_venv/lib/python3.10/site-packages/pandas/core/apply.py:837\u001B[0m, in \u001B[0;36mFrameApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    834\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw:\n\u001B[1;32m    835\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_raw()\n\u001B[0;32m--> 837\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/LAGT/lagt_venv/lib/python3.10/site-packages/pandas/core/apply.py:963\u001B[0m, in \u001B[0;36mFrameApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    962\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_standard\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 963\u001B[0m     results, res_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_series_generator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    965\u001B[0m     \u001B[38;5;66;03m# wrap results\u001B[39;00m\n\u001B[1;32m    966\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwrap_results(results, res_index)\n",
      "File \u001B[0;32m~/Projects/LAGT/lagt_venv/lib/python3.10/site-packages/pandas/core/apply.py:979\u001B[0m, in \u001B[0;36mFrameApply.apply_series_generator\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    976\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m option_context(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmode.chained_assignment\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    977\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(series_gen):\n\u001B[1;32m    978\u001B[0m         \u001B[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001B[39;00m\n\u001B[0;32m--> 979\u001B[0m         results[i] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    980\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(results[i], ABCSeries):\n\u001B[1;32m    981\u001B[0m             \u001B[38;5;66;03m# If we have a view on v, we need to make a copy because\u001B[39;00m\n\u001B[1;32m    982\u001B[0m             \u001B[38;5;66;03m#  series_generator will swap out the underlying data\u001B[39;00m\n\u001B[1;32m    983\u001B[0m             results[i] \u001B[38;5;241m=\u001B[39m results[i]\u001B[38;5;241m.\u001B[39mcopy(deep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m<timed exec>:10\u001B[0m, in \u001B[0;36m<lambda>\u001B[0;34m(row)\u001B[0m\n",
      "File \u001B[0;32m<timed exec>:4\u001B[0m, in \u001B[0;36mget_grecy_lemmata\u001B[0;34m(string, lemmatized_sentences, doc_id)\u001B[0m\n",
      "File \u001B[0;32m~/Projects/LAGT/lagt_venv/lib/python3.10/site-packages/spacy/language.py:1037\u001B[0m, in \u001B[0;36m__call__\u001B[0;34m(self, text, disable, component_cfg)\u001B[0m\n\u001B[1;32m   1035\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m   1036\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(proc, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__call__\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1037\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(Errors\u001B[38;5;241m.\u001B[39mE003\u001B[38;5;241m.\u001B[39mformat(component\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mtype\u001B[39m(proc), name\u001B[38;5;241m=\u001B[39mname))\n\u001B[1;32m   1038\u001B[0m error_handler \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefault_error_handler\n\u001B[1;32m   1039\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(proc, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mget_error_handler\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/Projects/LAGT/lagt_venv/lib/python3.10/site-packages/spacy/language.py:1128\u001B[0m, in \u001B[0;36m_ensure_doc\u001B[0;34m(self, doc_like)\u001B[0m\n\u001B[1;32m   1123\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m Doc(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvocab)\u001B[38;5;241m.\u001B[39mfrom_bytes(doc_like)\n\u001B[1;32m   1124\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(Errors\u001B[38;5;241m.\u001B[39mE1041\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mtype\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mtype\u001B[39m(doc_like)))\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_ensure_doc_with_context\u001B[39m(\n\u001B[1;32m   1127\u001B[0m     \u001B[38;5;28mself\u001B[39m, doc_like: Union[\u001B[38;5;28mstr\u001B[39m, Doc, \u001B[38;5;28mbytes\u001B[39m], context: _AnyContext\n\u001B[0;32m-> 1128\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Doc:\n\u001B[1;32m   1129\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call _ensure_doc to generate a Doc and set its context object.\"\"\"\u001B[39;00m\n\u001B[1;32m   1130\u001B[0m     doc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_doc(doc_like)\n",
      "File \u001B[0;32m~/Projects/LAGT/lagt_venv/lib/python3.10/site-packages/spacy/language.py:1117\u001B[0m, in \u001B[0;36mmake_doc\u001B[0;34m(self, text)\u001B[0m\n\u001B[1;32m   1115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_ensure_doc\u001B[39m(\u001B[38;5;28mself\u001B[39m, doc_like: Union[\u001B[38;5;28mstr\u001B[39m, Doc, \u001B[38;5;28mbytes\u001B[39m]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Doc:\n\u001B[1;32m   1116\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Create a Doc if need be, or raise an error if the input is not\u001B[39;00m\n\u001B[0;32m-> 1117\u001B[0m \u001B[38;5;124;03m    a Doc, string, or a byte array (generated by Doc.to_bytes()).\"\"\"\u001B[39;00m\n\u001B[1;32m   1118\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(doc_like, Doc):\n\u001B[1;32m   1119\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m doc_like\n",
      "\u001B[0;31mValueError\u001B[0m: [E088] Text of length 1419780 exceeds maximum of 1000000. The parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. This means long texts may cause memory allocation errors. If you're not using the parser or NER, it's probably safe to increase the `nlp.max_length` limit. The limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grecy_lemmatized_list = []\n",
    "def get_grecy_lemmata(string, lemmatized_sentences, doc_id):\n",
    "    if lemmatized_sentences == None:\n",
    "        lemmatized_sentences = from_string_to_lemsents(string)\n",
    "        grecy_lemmatized_list.append(doc_id)\n",
    "    return lemmatized_sentences\n",
    "\n",
    "sample_lemmatized_sentences = LAGT.sample(10).apply(lambda row: get_grecy_lemmata(row[\"string\"], row[\"lemmatized_sentences\"], row[\"doc_id\"]), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T23:18:59.137173Z",
     "start_time": "2024-01-16T22:16:58.740018Z"
    }
   },
   "id": "e31e2423065c010c",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "77"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grecy_lemmatized_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T23:18:59.980541Z",
     "start_time": "2024-01-16T23:18:59.549451Z"
    }
   },
   "id": "819118863f791d2c",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "LAGT.to_json(\"../data/large_files/LAGT_grecy_20240116.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T23:19:04.518599Z",
     "start_time": "2024-01-16T23:19:03.770583Z"
    }
   },
   "id": "2b2b46855d242ce4",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "s = sddk.cloudSession(\"sciencedata.dk\", \"SDAM_root\", \"648597@au.dk\")\n",
    "s.write_file(\"SDAM_data/AGT/LAGT_grecy_20240116.json\", LAGT)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2e93c867bff5254"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "lagt_kernel",
   "language": "python",
   "display_name": "lagt_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
